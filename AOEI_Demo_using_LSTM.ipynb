{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense,LSTM,Embedding,Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Intent Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10561, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kiyyoo dirama oso  eguti jirun na darbe tari a...</td>\n",
       "      <td>Question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meeti ree kuta 28ffaa</td>\n",
       "      <td>Question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kutaa digdami sadetaffa isiin egee dadhabee.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kutaa digdami sadetaffaa fiidagaa maali nuuraa...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nuuf jabbadhakaa warii Akka kotti kiyyoo jaala...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text     Intent\n",
       "0  Kiyyoo dirama oso  eguti jirun na darbe tari a...  Question \n",
       "1                              Meeti ree kuta 28ffaa  Question \n",
       "2       Kutaa digdami sadetaffa isiin egee dadhabee.   Negative\n",
       "3  Kutaa digdami sadetaffaa fiidagaa maali nuuraa...   Negative\n",
       "4  Nuuf jabbadhakaa warii Akka kotti kiyyoo jaala...   Positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:\\\\Users\\\\Moti\\Desktop\\\\Intent\\\\Meliha Research\\\\maliha_dataset_researchs.xlsx\"\n",
    "data=pd.read_excel(path, names=['Text','Intent'])\n",
    "data.sample(frac=1).reset_index(drop=True)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Intent', ylabel='count'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Intent', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive       4320\n",
       "Negative       3271\n",
       "Suggestion     1686\n",
       "Question        736\n",
       "Wish            546\n",
       "Name: Intent, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Intent\"].value_counts()\n",
    "#print(len('Gosa_miira'))\n",
    "#print(len('jechoota'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        kiyyoo dirama oso  eguti jirun na darbe tari a...\n",
       "1                                    meeti ree kuta 28ffaa\n",
       "2             kutaa digdami sadetaffa isiin egee dadhabee.\n",
       "3        kutaa digdami sadetaffaa fiidagaa maali nuuraa...\n",
       "4        nuuf jabbadhakaa warii akka kotti kiyyoo jaala...\n",
       "                               ...                        \n",
       "10556    isheenis namoota dogoggoraa waliin lafa dogogg...\n",
       "10557    vidiyichis battalumatti qoodamuun marsariitiiw...\n",
       "10558    gochiwwan qaamaa warraabbicha irratti ture bah...\n",
       "10559              jechi gurbbichaa altokkicha dhagahame. \n",
       "10560                           viidiyoo waraabaa jirtaa? \n",
       "Name: Text, Length: 10561, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,  200, 3024, 3025, 6010, 6011,\n",
       "          37,  192, 6012, 6013,  140,  325, 6014, 6015],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0, 5622,  438, 3332, 6016],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,  162, 3333, 6017,  326, 6018,  422],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,  162, 3333, 6019, 6020,  157, 6021,\n",
       "        6022, 3115,   47, 6023, 6024, 6025, 6026, 6027],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,   78, 6028, 3334,    4, 3116,  200, 3335]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer=Tokenizer(num_words=10000,split=\" \")\n",
    "tokenizer.fit_on_texts(data['Text'].values)\n",
    "x=tokenizer.texts_to_sequences(data['Text'].values)\n",
    "x=pad_sequences(x)\n",
    "x[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(50000, 128, input_length=x.shape[1]))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(250, return_sequences=True, dropout=0.3, recurrent_dropout=0.2))\n",
    "model.add(LSTM(250, dropout=0.3, recurrent_dropout=0.5))\n",
    "#model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.3))\n",
    "model.add(Dense(5, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 41, 128)           6400000   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 41, 128)           0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 41, 250)           379000    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 250)               501000    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 1255      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,281,255\n",
      "Trainable params: 7,281,255\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question  [0 0 1 0 0]\n",
      "Question  [0 0 1 0 0]\n",
      "Negative [1 0 0 0 0]\n",
      "Negative [1 0 0 0 0]\n",
      "Positive [0 1 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=pd.get_dummies(data['Intent']).values\n",
    "[print(data['Intent'][i],y[i]) for i in range(0,5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Traing and Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "141/141 - 199s - loss: 1.2117 - accuracy: 0.4970 - val_loss: 0.8017 - val_accuracy: 0.6953 - 199s/epoch - 1s/step\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[0;32m      2\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 30\n",
    "history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size,validation_data=(x_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_test, y_test,verbose=2)\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string])\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()\n",
    "plot_graphs(history, \"accuracy\")\n",
    "plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"LSTM-Intent_Classification_using_LSTM.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_intent = ['Kiyyoo dirama oso  eguti jirun na darbe tari ayaana moo sababa godhatu moyuu']\n",
    "seq = tokenizer.texts_to_sequences(new_intent)\n",
    "padded = pad_sequences(seq, maxlen=6000)\n",
    "pred = model.predict(padded)\n",
    "Intent = ['Question', 'Negative', 'Positive', 'Suggestion', 'Wish']\n",
    "print(pred, Intent[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print (data['Text'][i], predictions[i], y_test[i]) for i in range(0, 200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=metrics.confusion_matrix(y_test.argmax(axis=1), predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "FN = cm.sum(axis=1) - np.diag(cm)\n",
    "TP = np.diag(cm)\n",
    "TN = cm.sum() - (FP + FN + TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FP)\n",
    "print(FN)\n",
    "print(TP)\n",
    "print(TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=(TP+TN)/(TP+TN+FP+FN)\n",
    "precision = TP/(TP+FP)\n",
    "recall = TP/(TP+FN)\n",
    "f1_score = 2*precision*recall/(precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"recall  \", recall)\n",
    "print(\"precision\",precision)\n",
    "print(\"f1_score\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements = confusion_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(label, confusion_matrix):\n",
    "    col = confusion_matrix[:, label]\n",
    "    return confusion_matrix[label, label] / col.sum()\n",
    "    \n",
    "def recall(label, confusion_matrix):\n",
    "    row = confusion_matrix[label, :]\n",
    "    return confusion_matrix[label, label] / row.sum()\n",
    "\n",
    "def precision_macro_average(confusion_matrix):\n",
    "    rows, columns = confusion_matrix.shape\n",
    "    sum_of_precisions = 0\n",
    "    for label in range(rows):\n",
    "        sum_of_precisions += precision(label, confusion_matrix)\n",
    "    return sum_of_precisions / rows\n",
    "\n",
    "def recall_macro_average(confusion_matrix):\n",
    "    rows, columns = confusion_matrix.shape\n",
    "    sum_of_recalls = 0\n",
    "    for label in range(columns):\n",
    "        sum_of_recalls += recall(label, confusion_matrix)\n",
    "    return sum_of_recalls / columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"label precision recall\")\n",
    "for label in range(5):\n",
    "    print(f\"{label:5d} {precision(label, cm):9.3f} {recall(label, cm):6.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"precision total:\", precision_macro_average(cm))\n",
    "\n",
    "print(\"recall total:\", recall_macro_average(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements = confusion_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_small = [\"Positive\", \"Negative\", \"Suggestion\", \"Question\", \"Wish \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test).argmax(axis=-1)\n",
    "matrix = metrics.confusion_matrix(y_test.argmax(axis=-1), y_pred)\n",
    "plot_confusion_matrix(cm=matrix, normalize=True, classes=intent_small, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test).argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(cm, index=classes, columns=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
    "hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert.tokenization.bert_tokenization import FullTokenizer\n",
    "sentences = [\n",
    "  \"Play our song now\",\n",
    "  \"Rate this book as awful\"\n",
    "]\n",
    "\n",
    "pred_tokens = map(tokenizer.tokenize, sentences)\n",
    "pred_tokens = map(lambda tok: [\"[CLS]\"] + tok + [\"[SEP]\"], pred_tokens)\n",
    "pred_token_ids = list(map(tokenizer.convert_tokens_to_ids, pred_tokens))\n",
    "\n",
    "pred_token_ids = map(lambda tids: tids +[0]*(data.max_seq_len-len(tids)),pred_token_ids)\n",
    "pred_token_ids = np.array(list(pred_token_ids))\n",
    "\n",
    "predictions = model.predict(pred_token_ids).argmax(axis=-1)\n",
    "\n",
    "for text, label in zip(sentences, predictions):\n",
    "  print(\"text:\", text, \"\\nintent:\", classes[label])\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
