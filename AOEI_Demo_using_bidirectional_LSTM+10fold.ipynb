{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing important librarys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense,LSTM,Embedding,Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "import re\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from sklearn.model_selection import KFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10561, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kiyyoo dirama oso  eguti jirun na darbe tari a...</td>\n",
       "      <td>Question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meeti ree kuta 28ffaa</td>\n",
       "      <td>Question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kutaa digdami sadetaffa isiin egee dadhabee.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kutaa digdami sadetaffaa fiidagaa maali nuuraa...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nuuf jabbadhakaa warii Akka kotti kiyyoo jaala...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text     Intent\n",
       "0  Kiyyoo dirama oso  eguti jirun na darbe tari a...  Question \n",
       "1                              Meeti ree kuta 28ffaa  Question \n",
       "2       Kutaa digdami sadetaffa isiin egee dadhabee.   Negative\n",
       "3  Kutaa digdami sadetaffaa fiidagaa maali nuuraa...   Negative\n",
       "4  Nuuf jabbadhakaa warii Akka kotti kiyyoo jaala...   Positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('intent1-corrected.csv',names=['Text','Intent'],encoding=\"utf-8\")\n",
    "data.sample(frac=1).reset_index(drop=True)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Intent', ylabel='count'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Intent', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive       4320\n",
       "Negative       3271\n",
       "Suggestion     1686\n",
       "Question        736\n",
       "Wish            546\n",
       "Name: Intent, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Intent\"].value_counts()\n",
    "#print(len('Gosa_miira'))\n",
    "#print(len('jechoota'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preprocessing  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sen):\n",
    "    # Removing html tags\n",
    "    sentence = remove_tags(sen)\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    sentence = sen.lower()\n",
    "    sentence = re.sub(r'wo*w','wow', sentence)\n",
    "    sentence = re.sub(r'uu*f','uff', sentence)\n",
    "    return sentence\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "def remove_tags(Text):\n",
    "    return TAG_RE.sub('', Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(review_words):\n",
    "    with open('stopwords.txt')as stopfile:\n",
    "        stopwords=stopfile.read()\n",
    "        list=stopwords.split()\n",
    "        print(list)\n",
    "        with open(\"intent1.csv\") as workfile:\n",
    "            read_data=workfile.read()\n",
    "            data=read_data.split()\n",
    "            print(data)\n",
    "            for word1 in list:\n",
    "                for word2 in data:\n",
    "                    if word1==word2:\n",
    "                        return data.remove(list)\n",
    "                        print(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        kiyyoo dirama oso  eguti jirun na darbe tari a...\n",
       "1                                    meeti ree kuta 28ffaa\n",
       "2             kutaa digdami sadetaffa isiin egee dadhabee.\n",
       "3        kutaa digdami sadetaffaa fiidagaa maali nuuraa...\n",
       "4        nuuf jabbadhakaa warii akka kotti kiyyoo jaala...\n",
       "                               ...                        \n",
       "10556    isheenis namoota dogoggoraa waliin lafa dogogg...\n",
       "10557    vidiyichis battalumatti qoodamuun marsariitiiw...\n",
       "10558    gochiwwan qaamaa warraabbicha irratti ture bah...\n",
       "10559              jechi gurbbichaa altokkicha dhagahame. \n",
       "10560                           viidiyoo waraabaa jirtaa? \n",
       "Name: Text, Length: 10561, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,  200, 3022, 3023,   37,  193,  140,  325],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,  439, 3332],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,  162, 3333,  326,  423],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,  162, 3333,  157, 3113,   47],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,   79, 3334,    4, 3114,  200, 3335]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer=Tokenizer(num_words=4000,split=\" \")\n",
    "tokenizer.fit_on_texts(data['Text'].values)\n",
    "x=tokenizer.texts_to_sequences(data['Text'].values)\n",
    "x=pad_sequences(x)\n",
    "x[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(4000, 128, input_length=x.shape[1]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(300, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Bidirectional(LSTM(250, dropout=0.3, recurrent_dropout=0.2)))\n",
    "#model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.3))\n",
    "model.add(Dense(5, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question  [0 0 1 0 0]\n",
      "Question  [0 0 1 0 0]\n",
      "Negative [1 0 0 0 0]\n",
      "Negative [1 0 0 0 0]\n",
      "Positive [0 1 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=pd.get_dummies(data['Intent']).values\n",
    "[print(data['Intent'][i],y[i]) for i in range(0,5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing dataset Splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "17/17 - 128s - loss: 1.3955 - accuracy: 0.3879 - val_loss: 1.3519 - val_accuracy: 0.4051 - 128s/epoch - 8s/step\n",
      "Epoch 2/15\n",
      "17/17 - 139s - loss: 1.3068 - accuracy: 0.4712 - val_loss: 1.0791 - val_accuracy: 0.5845 - 139s/epoch - 8s/step\n",
      "Epoch 3/15\n",
      "17/17 - 167s - loss: 1.0576 - accuracy: 0.6070 - val_loss: 0.8390 - val_accuracy: 0.7014 - 167s/epoch - 10s/step\n",
      "Epoch 4/15\n",
      "17/17 - 173s - loss: 0.7052 - accuracy: 0.7411 - val_loss: 0.7171 - val_accuracy: 0.7345 - 173s/epoch - 10s/step\n",
      "Epoch 5/15\n",
      "17/17 - 149s - loss: 0.5504 - accuracy: 0.8031 - val_loss: 0.6033 - val_accuracy: 0.7747 - 149s/epoch - 9s/step\n",
      "Epoch 6/15\n",
      "17/17 - 178s - loss: 0.4435 - accuracy: 0.8374 - val_loss: 0.5368 - val_accuracy: 0.7974 - 178s/epoch - 10s/step\n",
      "Epoch 7/15\n",
      "17/17 - 185s - loss: 0.3859 - accuracy: 0.8585 - val_loss: 0.5122 - val_accuracy: 0.8097 - 185s/epoch - 11s/step\n",
      "Epoch 8/15\n",
      "17/17 - 238s - loss: 0.3507 - accuracy: 0.8659 - val_loss: 0.5004 - val_accuracy: 0.8239 - 238s/epoch - 14s/step\n",
      "Epoch 9/15\n",
      "17/17 - 262s - loss: 0.3242 - accuracy: 0.8729 - val_loss: 0.4761 - val_accuracy: 0.8320 - 262s/epoch - 15s/step\n",
      "Epoch 10/15\n",
      "17/17 - 267s - loss: 0.2925 - accuracy: 0.8893 - val_loss: 0.4613 - val_accuracy: 0.8358 - 267s/epoch - 16s/step\n",
      "Epoch 11/15\n",
      "17/17 - 272s - loss: 0.2682 - accuracy: 0.8964 - val_loss: 0.4407 - val_accuracy: 0.8476 - 272s/epoch - 16s/step\n",
      "Epoch 12/15\n",
      "17/17 - 229s - loss: 0.2511 - accuracy: 0.9046 - val_loss: 0.4572 - val_accuracy: 0.8471 - 229s/epoch - 13s/step\n",
      "Epoch 13/15\n",
      "17/17 - 232s - loss: 0.2463 - accuracy: 0.9040 - val_loss: 0.4505 - val_accuracy: 0.8504 - 232s/epoch - 14s/step\n",
      "Epoch 14/15\n",
      "17/17 - 240s - loss: 0.2254 - accuracy: 0.9131 - val_loss: 0.4575 - val_accuracy: 0.8462 - 240s/epoch - 14s/step\n",
      "Epoch 15/15\n",
      "17/17 - 231s - loss: 0.2210 - accuracy: 0.9119 - val_loss: 0.4507 - val_accuracy: 0.8609 - 231s/epoch - 14s/step\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "epochs = 15\n",
    "history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size,validation_data=(x_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object '<keras.engine.sequential.Sequential object at 0x000001FA9BCA5310>' (type <class 'keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\parallel.py:862\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 862\u001b[0m     tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ready_batches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m queue\u001b[38;5;241m.\u001b[39mEmpty:\n\u001b[0;32m    864\u001b[0m     \u001b[38;5;66;03m# slice the iterator n_jobs * batchsize items at a time. If the\u001b[39;00m\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;66;03m# slice returns less than that, then the current batchsize puts\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    868\u001b[0m     \u001b[38;5;66;03m# accordingly to distribute evenly the last items between all\u001b[39;00m\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# workers.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\queue.py:168\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[1;32m--> 168\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\parallel.py:873\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    870\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_effective_n_jobs\n\u001b[0;32m    871\u001b[0m big_batch_size \u001b[38;5;241m=\u001b[39m batch_size \u001b[38;5;241m*\u001b[39m n_jobs\n\u001b[1;32m--> 873\u001b[0m islice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbig_batch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(islice) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:59\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Capture the thread-local scikit-learn configuration at the time\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Parallel.__call__ is issued since the tasks can be dispatched\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# in a different thread depending on the backend and on the value of\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# pre_dispatch and n_jobs.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m---> 59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:268\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m--> 268\u001b[0m         \u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    269\u001b[0m         X,\n\u001b[0;32m    270\u001b[0m         y,\n\u001b[0;32m    271\u001b[0m         scorers,\n\u001b[0;32m    272\u001b[0m         train,\n\u001b[0;32m    273\u001b[0m         test,\n\u001b[0;32m    274\u001b[0m         verbose,\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    276\u001b[0m         fit_params,\n\u001b[0;32m    277\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[0;32m    278\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    279\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[0;32m    280\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:79\u001b[0m, in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m     74\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot clone object. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     75\u001b[0m                 \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou should provide an instance of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     76\u001b[0m                 \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscikit-learn estimator instead of a class.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     77\u001b[0m             )\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 79\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m     80\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot clone object \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     81\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mit does not seem to be a scikit-learn \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     82\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator as it does not implement a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     83\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m method.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mrepr\u001b[39m(estimator), \u001b[38;5;28mtype\u001b[39m(estimator))\n\u001b[0;32m     84\u001b[0m             )\n\u001b[0;32m     86\u001b[0m klass \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\n\u001b[0;32m     87\u001b[0m new_object_params \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mget_params(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot clone object '<keras.engine.sequential.Sequential object at 0x000001FA9BCA5310>' (type <class 'keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method."
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(model, x_test, y_test, scoring = 'r2', cv = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_test, y_test,verbose=2)\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Intent_Classification.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_intent = ['Kiyyoo dirama oso  eguti jirun na darbe tari ayaana moo sababa godhatu moyuu']\n",
    "seq = tokenizer.texts_to_sequences(new_intent)\n",
    "padded = pad_sequences(seq, maxlen=6000)\n",
    "pred = model.predict(padded)\n",
    "Intent = ['Question', 'Negative', 'Positive', 'Suggestion', 'Wish']\n",
    "print(pred, Intent[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print (data['Text'][i], predictions[i], y_test[i]) for i in range(0, 400)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()\n",
    "  \n",
    "plot_graphs(history, \"accuracy\")\n",
    "plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=metrics.confusion_matrix(y_test.argmax(axis=1), predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "FN = cm.sum(axis=1) - np.diag(cm)\n",
    "TP = np.diag(cm)\n",
    "TN = cm.sum() - (FP + FN + TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FP)\n",
    "print(FN)\n",
    "print(TP)\n",
    "print(TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = TP/(TP+FP)\n",
    "recall = TP/(TP+FN)\n",
    "f1_score = 2*precision*recall/(precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"precision\",precision)\n",
    "print(\"recall  \", recall)\n",
    "print(\"f1_score\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements = confusion_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
